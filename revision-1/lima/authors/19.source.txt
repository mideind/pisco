<|user|>
Write an abstract for a machine learning paper that shows how to train a chatbot by fine-tuning a pretrained language model on 1000 carefully curated examples.
<|system|>
Language models have shown impressive results through a combination of unsupervised training, large scale instruction tuning, and reinforcement learning. We explore the relative importance of these approaches by fine-tuning a language model on only 1000 high-quality examples, and demonstrate remarkably strong performance. The training data comprises of carefully curated examples from [add sources]. We find that with only a handful of demonstrations, the model can quickly learn to follow specific answer formats, answering complex queries from planning trip itineraries to speculating about alternative histories. In a controlled human study, we observe that our simple approach brings the model to the same level of performance as industry-grade chatbots. These results support a hypothesis that almost all knowledge in large language models is learnt during pre-training, and only limited instruction tuning data is necessary to teach models to focus on modes corresponding to high quality outputs.